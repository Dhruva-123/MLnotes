1. Linear Models (Foundational)
These are your building blocks for almost every other model.

âœ… Perceptron

âœ… Adaline (SGD for regression)

âœ… Linear Regression

âœ… Logistic Regression (Binary + Multiclass softmax)

âœ… Ridge Regression

âœ… Lasso Regression

âœ… Elastic Net

âœ… Polynomial Regression

ğŸ” Learn: cost functions, gradient descent, closed-form vs iterative, regularization tradeoffs

2. Probabilistic Models
Youâ€™ll learn to model uncertainty, distributions, and generative processes.

âœ… Naive Bayes (Gaussian, Bernoulli, Multinomial)

âœ… Gaussian Discriminant Analysis (GDA)

âœ… Bayesian Linear Regression

âœ… MAP vs MLE estimation

âœ… Log-Likelihoods & prior/posterior math

ğŸ” Learn: likelihoods, conjugate priors, generative vs discriminative debate

3. Tree-Based Models
You already started here. Now you go full-depth.

âœ… Decision Trees (ID3, CART â€“ Gini vs Entropy)

âœ… Random Forests

âœ… Extra Trees (Extremely Randomized Trees)

âœ… Gradient Boosting (from scratch)

âœ… XGBoost / LightGBM (black-box level + intuition)

ğŸ” Learn: biasâ€“variance control, overfitting, feature bagging, ensemble stacking

4. Kernel and Margin-Based Models
SVMs are the crown jewels of classical ML. Master their math.

âœ… Hard-margin SVM

âœ… Soft-margin SVM (hinge loss + slack vars)

âœ… Dual SVM (Lagrangian, KKT conditions)

âœ… Kernel SVM (RBF, polynomial, custom)

âœ… SMO (Sequential Minimal Optimization)

âœ… Kernel Ridge Regression

ğŸ” Learn: duality, QP solvers, kernel trick, margin maximization

5. Instance-Based Methods
Fast, lazy models. Great sanity checks.

âœ… K-Nearest Neighbors (KNN)

âœ… Radius Neighbors

âœ… Distance metrics: Euclidean, Manhattan, Mahalanobis, Cosine

ğŸ” Learn: curse of dimensionality, instance efficiency, distance geometry

6. Unsupervised Models
Clustering and dimensionality reduction. These are powerful for EDA and pipeline prep.

âœ… K-Means Clustering

âœ… Gaussian Mixture Models (GMM)

âœ… Hierarchical Clustering (Agglomerative)

âœ… DBSCAN

âœ… PCA

âœ… LDA (as dimensionality reducer)

âœ… t-SNE / UMAP (black-box intuition)

ğŸ” Learn: eigenvectors, latent space geometry, density modeling

7. Model Selection, Evaluation & Tuning
This is glue code mastery â€” the infrastructure pros use.

âœ… StratifiedKFold, GroupKFold

âœ… Cross-validation strategies

âœ… Grid Search / Random Search / Bayesian optimization

âœ… Learning curves, Validation curves

âœ… Biasâ€“Variance Decomposition

âœ… Confusion matrix, ROC/AUC, Log Loss, F1-score

ğŸ” Learn: when models fail, how to tune them, and how to compare them fairly

8. Bonus: Other Classical Models
(These show up in interviews, older papers, or special use-cases)

âœ… Linear Discriminant Analysis (LDA) as a classifier

âœ… Quadratic Discriminant Analysis (QDA)

âœ… Isotonic Regression

âœ… HMM (Hidden Markov Models) â€“ especially for sequence modeling

âœ… Kalman Filters (for time-series prediction, control systems)